# 单机版缓存

## 架构

### 1.并发安全的cache接口

```go
type CCache interface {
	Get(key string, load Loader) (val interface{})
}

type ccache struct {
	mu sync.Mutex
	c  Cache
}
```

### 2.通用的非并发安全的缓存接口

常用的缓存淘汰策略有以下

- 先进先出算法（FIFO）
- Least Frequently Used（LFU）:淘汰一定时期内被访问次数最少的页面，以次数作为参考
- Least Recently Used（LRU）:淘汰最长时间未被使用的页面，以时间作为参考

使用不同缓存淘汰策略的缓存都实现以下接口

```go
type Cache interface {
	Get(key string) (val interface{}, ok bool)
	Set(key string, val interface{})
}
```

## 实现

### 1.LRU缓存的实现

```go
type Cache struct {
	cap   int // 容量
	ll    *list.List  // 使用双向列表来排序，最近使用在前
	cache map[string]*list.Element  // 缓存
}

// Get get the key's value
func (c *Cache) Get(key string) (interface{}, bool) {
	if ele, ok := c.cache[key]; ok {
		c.ll.MoveToFront(ele) // 更新该缓存的次序
		return ele.Value.(*entry).value, true
	}
	return nil, false
}

// Set set the key's value
func (c *Cache) Set(key string, val interface{}) {
	ele := c.ll.PushFront(&entry{key, val})
	c.cache[key] = ele
	if c.cap != 0 && c.ll.Len() > c.cap {
		c.RemoveOldest() // 去掉链表最后一个
	}
}
```

### 2.并发安全缓存的实现

缓存更新策略：

- Cache-Aside
- Read-Through
- Write-Through
- Write-Behind

Cache-Aside实现如下

```go
func (cc *ccache) Get(key string, load Loader) interface{} {
	cc.mu.Lock()
	if v, ok := cc.c.Get(key); ok {
		cc.mu.Unlock()
		return v
	}
	cc.mu.Unlock()

  // load花费时间较长，不应该且不需要加锁
  v := load()
  
	cc.mu.Lock()
	cc.c.Set(key, v)
	cc.mu.Unlock()
	return v
}
```

## 优化

### 1.使用singleflight避免缓存击穿

- ccache增加属性`sl *singleflight.Group`
- `v := cc.sl.Do(key, load)`

